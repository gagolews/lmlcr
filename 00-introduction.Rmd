<!--
kate: indent-width 4; word-wrap-column 74; default-dictionary en_AU
Copyright (C) 2020-2021, Marek Gagolewski <https://www.gagolewski.com>
This material is licensed under the Creative Commons BY-NC-ND 4.0 License.
-->

# Preface  {.unnumbered}



> This is a slightly older version of the forthcoming textbook (ETA 2022)
preliminarily entitled *Machine Learning in R from Scratch*
by [Marek Gagolewski](https://www.gagolewski.com), which is now undergoing
a major revision (when I am not busy with other projects).
What you see here is still quite readable, though.
I will share a new draft once it's ripe. Stay tuned.


Copyright (C) 2020-2021, [Marek Gagolewski](https://www.gagolewski.com).

This material is licensed under the Creative Commons
[Attribution-NonCommercial-NoDerivatives 4.0 International](https://creativecommons.org/licenses/by-nc-nd/4.0/)
License (CC BY-NC-ND 4.0).

You can access this book at:

* https://lmlcr.gagolewski.com/ (a browser-friendly version)
* https://lmlcr.gagolewski.com/lmlcr.pdf (PDF)
* https://github.com/gagolews/lmlcr (source code)



<!-- ![](figures/cover) -->


#### Aims and Scope  {.unnumbered}


Machine learning has numerous exciting real-world applications,
including stock market prediction, speech recognition,
computer-aided medical diagnosis, content and product recommendation,
anomaly detection in security camera footage, game playing,
autonomous vehicle operation, and many others.

In this book we will take an unpretentious glance at the most fundamental
algorithms that have stood the test of time and which  form
the basis for state-of-the-art solutions of modern AI,
which is principally (big) data-driven.
We will learn how to use the R language [@rproject]
for implementing various stages
of data processing and modelling activities.
For a more in-depth treatment of R, refer to this book's Appendices
and, for instance, [@Rintro; @rprogdatascience; @r4ds].

These pages contain solid underpinnings for further studies
related to statistical learning, machine learning
data science, data analytics, and artificial intelligence,
including [@islr; @esl; @bishop].
We will also appreciate the vital role of mathematics as a universal
language for formalising data-intense problems and communicating their
solutions. The book is aimed at readers who are yet to be fluent with
university-level linear algebra, calculus and probability theory,
such as 1st year undergrads or those who have forgotten
all the maths they have learned and need a gentle, non-invasive,
yet rigorous introduction to the topic.
For a nice, machine learning-focused introduction to mathematics alone,
see, e.g., [@mml].


<!-- TODO: This book is structured as follows. -->

<!-- TODO: This book is non-standard in the way that:
* it doesn't assume that the reader is familiar with the concept
of probability, unlike many other books on statistical learning (especially with the
use of the R language)
* it only assumes high school-level mathematics; basic linear algebra concepts
(of which matrix multiplication is the most difficult one) are explained;
there is some reference to function differentiation, however the material is optional
and marked with an asterisk;
I am aware of the fact that some readers might struggle with the $\sum$ notation
for summation, but this is explained in the book;
I hope this book is a nice appreciation of the higher maths courses such as
linear algebra, calculus, discrete maths as well as probability and statistics
* then, once the math groundwork is laid, the reader will be ready for other
excellent books, like ESL, Bishop etc.
* it takes an algorithmic approach to the description of machine learning models
(yet, the models are not treated as black-boxes; we don't just apply functions
from different packages, but try to implement them on our own)
* it doesn't  assume any prior exposure to programming languages;
essential R basics are introduced in a rigorous manner and are self-contained;
it's not going to be easy, but all the building blocks (together with exercises)
are provided
* it demystifies and deconstructs the "coolness" of AI -- putting
all the hype aside, super-duper-tensor-GPU-cloud-self-driving-1-billion-revenue-
you-must-buy-our-products, it demonstrates that the basic concepts behind most methods
have been known for decades (basically, our computers are now much faster
and we have much more data, that's it); you don't need to be excited
about each new product, new toolbox, new algorithms (and don't FOMO!);
stay calm, it's just an old dog that learned new tricks.

instead of finding examples of datasets where ml methods work
("good datasets are hard to find")
the author took a few realistic databases and.... well, showed
how to solve the problems with the methods that don't work ;)


you might want to become a ML engineer or data analyst/scientist
or use the methods in your research

greedy companies store a lot of data about their customers --
you might want to understand the principles behind the methods they use
to recommend you that ad or product
-->




#### About the Author  {.unnumbered}

[Marek Gagolewski](https://www.gagolewski.com)
(pronounced like Mark Gaggle-Eve-Ski)
is currently a Senior Lecturer in Applied
AI at Deakin University in Melbourne, VIC, Australia
and an Associate Professor in Data Science (on long-term leave)
at Faculty of Mathematics and Information Science, Warsaw University
of Technology, Poland.

He is actively involved in developing *usable* free (libre) and open source
software, with particular focus on data science and machine learning.
He is the main author and maintainer of
[stringi](https://stringi.gagolewski.com) â€“ one of the most often
downloaded R packages (with over 33,000,000 downloads) that aims at natural
language and string processing as well as the Python and R package
[genieclust](https://genieclust.gagolewski.com) implementing
the fast and robust hierarchical clustering
algorithm *Genie* with noise point detection.

He's an author of more than 75 publications on machine learning and
optimisation algorithms, data aggregation and clustering, statistical
modelling, and scientific computing.
*Explaining* of things matters to him more than merely tuning the knobs
so as to increase a chosen performance metric (with uncontrollable consequences
to other ones); the latter belongs to technology and wizardry,
not science.

Moreover, Marek taught various courses
related to R and Python programming, algorithms, data science,
and machine learning in Australia, Poland, and Germany
(e.g., at [Data Science Retreat](https://datascienceretreat.com)).







#### Acknowledgements  {.unnumbered}

This book has been prepared with pandoc, Markdown, and GitBook.
R code chunks have been processed with knitr.
A little help of bookdown, good ol' Makefiles, and shell scripts
did the trick.


```{r,echo=FALSE}
library("knitr")
library("bookdown")
library("stringi")
fs <- list.files(".", "\\.Rmd$", full=TRUE)
pkgs <- stri_unique(stri_sort(unlist(lapply(fs, function(f)
    na.omit(stri_match_first_regex(
        readLines(f), "^library\\(['\"]?(.*?)['\"]?\\)")[,2])))))
```

The following R packages are used or referred to in the text:
`r stri_flatten(pkgs, collapse=", ")`.

During the writing of this book, I've been listening to the music
featuring John Coltrane, Krzysztof Komeda,
Henry Threadgill, Albert Ayler, Paco de Lucia, and Tomatito.



{ LATEX \mainmatter }

